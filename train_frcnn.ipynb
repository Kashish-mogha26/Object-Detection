{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_frcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpyNQSvxuyqOqd9nDMKi7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kashish-mogha26/Object-Detection/blob/master/train_frcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul0jVr8g-nRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "105d88d3-a40d-439d-e14d-9c490276af19"
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "import math\n",
        "import cv2\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "from keras.engine import Layer, InputSpec\n",
        "from keras import initializers, regularizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDwpQw14_H5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\t# Print the process or not\n",
        "\t\tself.verbose = True\n",
        "\n",
        "\t\t# Name of base network\n",
        "\t\tself.network = 'vgg'\n",
        "\n",
        "\t\t# Setting for data augmentation\n",
        "\t\tself.use_horizontal_flips = False\n",
        "\t\tself.use_vertical_flips = False\n",
        "\t\tself.rot_90 = False\n",
        "\n",
        "\t\t# Anchor box scales\n",
        "\t\tself.anchor_box_scales = [64, 128, 256] \n",
        "\n",
        "\t\t# Anchor box ratios\n",
        "\t\tself.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
        "\n",
        "\t\t# Size to resize the smallest side of the image\n",
        "\t\tself.im_size = 300\n",
        "\n",
        "\t\t# image channel-wise mean to subtract\n",
        "\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n",
        "\t\tself.img_scaling_factor = 1.0\n",
        "\n",
        "\t\t# number of ROIs at once\n",
        "\t\tself.num_rois = 4\n",
        "    # stride at the RPN (this depends on the network configuration)\n",
        "\t\tself.rpn_stride = 16\n",
        "\n",
        "\t\tself.balanced_classes = False\n",
        "\n",
        "\t\t# scaling the stdev\n",
        "\t\tself.std_scaling = 4.0\n",
        "\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "\t\t# overlaps for RPN\n",
        "\t\tself.rpn_min_overlap = 0.3\n",
        "\t\tself.rpn_max_overlap = 0.7\n",
        "\n",
        "\t\t# overlaps for classifier ROIs\n",
        "\t\tself.classifier_min_overlap = 0.1\n",
        "\t\tself.classifier_max_overlap = 0.5\n",
        "\n",
        "\t\t# placeholder for the class mapping, automatically generated by the parser\n",
        "\t\tself.class_mapping = None\n",
        "\n",
        "\t\tself.model_path = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCs-lZEw_2db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(input_path):\n",
        "\t\"\"\"Parse the data from annotation file\n",
        "\t\n",
        "\tArgs:\n",
        "\t\tinput_path: annotation file path\n",
        "\t\"\"\"\n",
        "\tfound_bg = False\n",
        "\tall_imgs = {}\n",
        "\n",
        "\tclasses_count = {}\n",
        "\n",
        "\tclass_mapping = {}\n",
        "\n",
        "\tvisualise = True\n",
        "\n",
        "\ti = 1\n",
        "\t\n",
        "\twith open(input_path,'r') as f:\n",
        "\n",
        "\t\tprint('Parsing annotation files')\n",
        "\n",
        "\t\tfor line in f:\n",
        "\n",
        "\t\t\t# Print process\n",
        "\t\t\tsys.stdout.write('\\r'+'idx=' + str(i))\n",
        "\t\t\ti += 1\n",
        "\n",
        "\t\t\tline_split = line.strip().split(',')\n",
        "\n",
        "\t\t\t\n",
        "\n",
        "\t\t\t(filename,x1,y1,x2,y2,class_name) = line_split\n",
        "\n",
        "\n",
        "\t\t\tif class_name not in classes_count:\n",
        "\t\t\t\tclasses_count[class_name] = 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tclasses_count[class_name] += 1\n",
        "\n",
        "\t\t\tif class_name not in class_mapping:\n",
        "\t\t\t\tif class_name == 'bg' and found_bg == False:\n",
        "\t\t\t\t\tprint('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n",
        "\t\t\t\t\tfound_bg = True\n",
        "\t\t\t\tclass_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "\t\t\tif filename not in all_imgs:\n",
        "\t\t\t\tall_imgs[filename] = {}\n",
        "\t\t\t\t\n",
        "\t\t\t\timg = cv2.imread(filename)\n",
        "\t\t\t\t(rows,cols) = img.shape[:2]\n",
        "\t\t\t\tall_imgs[filename]['filepath'] = filename\n",
        "\t\t\t\tall_imgs[filename]['width'] = cols\n",
        "\t\t\t\tall_imgs[filename]['height'] = rows\n",
        "\t\t\t\tall_imgs[filename]['bboxes'] = []\n",
        "\t\t\t\t# if np.random.randint(0,6) > 0:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'trainval'\n",
        "\t\t\t\t# else:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'test'\n",
        "\n",
        "\t\t\tall_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n",
        "\n",
        "\n",
        "\t\tall_data = []\n",
        "\t\tfor key in all_imgs:\n",
        "\t\t\tall_data.append(all_imgs[key])\n",
        "   # make sure the bg class is last in the list\n",
        "\t\tif found_bg:\n",
        "\t\t\tif class_mapping['bg'] != len(class_mapping) - 1:\n",
        "\t\t\t\tkey_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n",
        "\t\t\t\tval_to_switch = class_mapping['bg']\n",
        "\t\t\t\tclass_mapping['bg'] = len(class_mapping) - 1\n",
        "\t\t\t\tclass_mapping[key_to_switch] = val_to_switch\n",
        "\t\t\n",
        "\t\treturn all_data, classes_count, class_mapping"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}